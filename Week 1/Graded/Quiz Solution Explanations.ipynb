{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Which of the following is not one of Laney’s 3Vs?**\n",
    "\n",
    "Answer: Versatility\n",
    "\n",
    "*Explanation*: Laney’s 3Vs stand for Volume, Variety, and Velocity, which are three defining properties of big data. \n",
    "- **Volume** refers to the amount of data \n",
    "- **Variety** refers to the different types of data\n",
    "- **Velocity** refers to the speed at which data is generated and processed. \n",
    "\n",
    "**Versatility is not one of these three properties.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Which of the following best matches the meaning of \"velocity\" in the general context of Big Data?**\n",
    "\n",
    "Answer: The rate at which data is being generated\n",
    "\n",
    "*Explanation*: In the context of Big Data, \"velocity\" refers to the speed at which data is generated, collected, and analyzed. It emphasizes the real-time or near real-time nature of data processing and the rapid pace at which data flows into systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **True or False: A \"combining stage\" working with data would correspond with the Map stage of MapReduce.**\n",
    "\n",
    "Answer: False\n",
    "\n",
    "*Explanation*: In MapReduce, the combining stage refers to an optional step where local reduction operations are performed before the final reduce stage. The Map stage is responsible for processing input data and producing intermediate key-value pairs, but it doesn't correspond to the combining stage. The combining stage is typically used to optimize and reduce data before the final reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **True or False: There must always be a reduction step in MapReduce**\n",
    "\n",
    "Answer: False\n",
    "\n",
    "*Explanation*: While the \"Reduce\" step is a key component of the MapReduce paradigm, it is not strictly necessary in all implementations. Sometimes, the map phase itself can produce the final output without needing an additional reduction step, depending on the nature of the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **True or False: We are able to apply distributed computing solutions like MapReduce to large datasets because we are able to subdivide the data into discrete, independently-processable components (such as lines of a file) without major inter-component dependencies.**\n",
    "\n",
    "Answer: True\n",
    "\n",
    "*Explanation*: Distributed computing solutions like MapReduce work effectively on large datasets because the data can be divided into independent chunks that can be processed in parallel without major dependencies between them. This parallel processing capability allows for efficient handling and analysis of large-scale data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **Adding more computing power to existing machines is an example of which type of scaling?**\n",
    "\n",
    "Answer: Vertical scaling\n",
    "\n",
    "*Explanation*: Vertical scaling, also known as \"scaling up,\" involves adding more power (such as CPU, RAM, or storage) to an existing machine to enhance its performance. This contrasts with horizontal scaling, which involves adding more machines to a system to distribute the load."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. **Which of the following is not a main Hadoop module discussed in Week 1?**\n",
    "\n",
    "Answer: Hadoop Assembler\n",
    "\n",
    "**Explanation*: The main Hadoop modules discussed typically include Hadoop Common, Hadoop Distributed File System (HDFS), Hadoop Yet Another Resource Negotiator (YARN), and Hadoop MapReduce. Hadoop Assembler is not one of the core modules."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
