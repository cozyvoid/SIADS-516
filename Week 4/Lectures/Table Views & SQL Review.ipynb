{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Spark DataFrame Views**\n",
    "- Spark DataFrames can have views created for them, which can be temporary or permanent. Temporary views are preferred for simplicity and disappear after the Spark session ends.\n",
    "- Global views are available for data sharing across multiple Spark applications but are not covered in this context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Creating Temporary Views**\n",
    "- Use the `CreateOrReplaceTempView` function to create a temporary view from a DataFrame.\n",
    "- The name of the view is often the same as the DataFrame but can be different as needed.\n",
    "- These views allow SQL queries to be issued using the `SparkSession` object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **SQL Basics in Spark**\n",
    "- Focus is on the SQL `SELECT` statement to query data from data frames that can be populated from various file types like JSON or CSV.\n",
    "- Basic SQL syntax includes selecting columns from a table, filtering with `WHERE` conditions, ordering results, and using `DISTINCT` to ensure uniqueness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **SQL Functions and Clauses**\n",
    "- **Distinct:** Removes duplicates using `SELECT DISTINCT`.\n",
    "- **Where Clause**: Filters rows based on conditions using operators such as =, !=, >, <, etc.\n",
    "- **In and Between**: Filters using a specified set of values or a range.\n",
    "- **Like and Wildcards**: Use of % and _ with `LIKE` for pattern matching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **NULL Handling in SQL**\n",
    "- `NULL` in SQL represents no value, similar to `None` in Python.\n",
    "- Use `WHERE column IS NULL` to filter for null values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **Ordering and Grouping**\n",
    "- Use `ORDER BY` to sort results, default in ascending order unless `DESC` is specified.\n",
    "- Group results with `GROUP BY`, and each selected column must be in the `GROUP BY` clause or be an aggregation function like `SUM`, `COUNT`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. **Advanced SQL Queries**\n",
    "- **Having Clause**: Applies conditions to aggregate functions, used post-grouping.\n",
    "- **Aliasing**: Use `AS` to rename columns in the result set for readability.\n",
    "- **Table Sampling**: Use `TABLESAMPLE` to operate on a subset of data, useful for exploratory analysis on large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. **Formatting and Best Practices**\n",
    "- Triple-quoted strings for SQL queries offer readability and avoid cumbersome line continuation characters.\n",
    "- Use capital letters for SQL reserved words and lowercase for variables/column names based on convention though not mandatory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By understanding these concepts, the user can efficiently run SQL queries directly on Spark DataFrames, leveraging the power of Spark while utilizing the familiar syntax of SQL for data manipulation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
