{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Question 1: Which of the following is true?\n",
    "- **RDD Actions return non-RDDs**: True. Actions in RDDs return non-RDD values, such as counts or collected data.\n",
    "- **Spark Datasets are currently compatible with Python**: False. Spark Datasets are not fully compatible with Python; they are more commonly used with Scala and Java.\n",
    "- **SparkContext is considered to be the entry-point for working with Spark dataframes**: False. The entry-point for working with Spark DataFrames is `SparkSession`, not `SparkContext`.\n",
    "- **RDD stands for Resilient Dynamic Dataset**: False. RDD stands for Resilient Distributed Dataset.\n",
    "\n",
    "**Correct Answer:** RDD Actions return non-RDDs\n",
    "\n",
    "### Question 2: Which of the following are ways to display or retrieve data from a Spark dataframe?\n",
    "- **SparkDF.show()**: True. This method displays the DataFrame.\n",
    "- **SparkDF.first()**: True. This method returns the first row of the DataFrame.\n",
    "- **SparkDF.head(n)**: True. This method returns the first `n` rows of the DataFrame.\n",
    "- **SparkDF.take(n)**: True. This method returns the first `n` rows as a list.\n",
    "\n",
    "**Correct Answer:** All options are correct.\n",
    "\n",
    "### Question 3: True or False: “toDF()” is a method to create a new Spark dataframe comprised by selected columns of a pre-existing one\n",
    "- **True**: False. The `toDF()` method is used to convert an RDD to a DataFrame, not to select columns from an existing DataFrame.\n",
    "- **False**: True.\n",
    "\n",
    "**Correct Answer:** False\n",
    "\n",
    "### Question 4: Which of the following is a method to create an instance of a given dataframe TheDF with a new column called Weight_Unadjusted, initialized as a copy of a pre-existing column called Weight?\n",
    "- **TheDF.withColumn(“Weight_Unadjusted”, “Weight”)**: False. This syntax is incorrect.\n",
    "- **TheDF.withColumn(“Weight_Unadjusted”, col(“Weight”))**: True. This is the correct syntax to create a new column.\n",
    "- **TheDF.withColumn(col(“Weight_Unadjusted”), “Weight”)**: False. This syntax is incorrect.\n",
    "\n",
    "**Correct Answer:** TheDF.withColumn(“Weight_Unadjusted”, col(“Weight”))\n",
    "\n",
    "### Question 5: Which of the following is not usable to describe a dataframe?\n",
    "- **df.columns**: True. This method returns the column names.\n",
    "- **df.dtypes**: True. This method returns the data types of each column.\n",
    "- **df.count()**: True. This method returns the number of rows.\n",
    "- **df.rows()**: False. This method does not exist.\n",
    "\n",
    "**Correct Answer:** df.rows()\n",
    "\n",
    "### Question 6: Which of the following functions/methods creates a row for each value in a given list (or array, or similar structure)?\n",
    "- **toDF()**: False. This method converts an RDD to a DataFrame.\n",
    "- **explode()**: True. This method creates a new row for each element in the given array or map column.\n",
    "- **groupBy()**: False. This method groups the DataFrame using the specified columns.\n",
    "- **filter()**: False. This method filters rows based on a condition.\n",
    "\n",
    "**Correct Answer:** explode()\n",
    "\n",
    "### Question 7: When working with a Spark dataframe, to make a new column that is assigned to one value/expression if a condition is fulfilled, and another value/expression if the condition is unfulfilled, what sequence of methods would be used?\n",
    "- **when().else()**: False. This syntax is incorrect.\n",
    "- **if().else()**: False. This syntax is incorrect.\n",
    "- **if().elif().else()**: False. This syntax is incorrect.\n",
    "- **when().otherwise()**: True. This is the correct syntax to create conditional columns.\n",
    "\n",
    "**Correct Answer:** when().otherwise()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
